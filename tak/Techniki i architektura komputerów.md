## Model architekturalny komputera wg. von Neumanna a model obliczeniowy komputera na podstawie maszyny Turinga i ich rola w informatyce.

### von Neumann
Model architekturalny komputera wg. von Neumanna opiera siÄ™ na idei, Å¼e komputer skÅ‚ada siÄ™ z czterech gÅ‚Ã³wnych elementÃ³w:
- PamiÄ™ci komputera â€“ zawiera dane programu i jego instrukcje (wspÃ³lna pamiÄ™Ä‡ na obie te rzeczy)
- Jednostki sterujÄ…cej â€“ pobiera dane i instrukcje z pamiÄ™ci i dba o ich sekwencyjne przetwarzanie
- Jednostki arytmetyczno/logicznej â€“ wykonuje podstawowe operacje arytmetyczne
- UrzÄ…dzeÅ„ wejÅ›cia/wyjÅ›cia â€“ sÅ‚uÅ¼Ä… do interakcji z operatorem

**Model ten jest uwaÅ¼any za jeden z pierwszych formalnych modeli komputera**.

- Obliczenia sÄ… wykonywane na danych zapisanych w pamiÄ™ci i rejestrach komputera
- KolejnoÅ›Ä‡ wykonywania instrukcji jest ustalona przez programistÄ™:
	- Poprzez kolejnoÅ›Ä‡ ich zapisu
	- Poprzez instrukcjÄ™ przemieszczenia (zmiany) sterowania: skok (go to), wywoÅ‚anie podprogramu (np. wywoÅ‚anie funkcji), powrÃ³t z podprogramu (return) itp.
- KolejnoÅ›Ä‡ instrukcji jest wyznaczana przez **licznik rozkazÃ³w (program counter)** â€“ zawiera on adres nastÄ™pnej instrukcji w pamiÄ™ci po aktualnie wykonywanej
- JeÅ›li aktualna instrukcja nie zawiera rozkazu zmiany sterowania, to ustawia ona nowÄ… zawartoÅ›Ä‡ licznika rozkazÃ³w â€“ podaje nowy adres nastÄ™pnej instrukcji do wykonania
- Korzysta z **jÄ™zykÃ³w imperatywnych** Â­â€“ takich jÄ™zykÃ³w programowania, w ktÃ³rych programista okreÅ›la bezpoÅ›rednio (explicite) i dokÅ‚adnie jakie obliczenia majÄ… siÄ™ wykonaÄ‡ i dokÅ‚adnie w jakiej kolejnoÅ›ci

> [!info] Model obliczeniowy
>  okreÅ›la w jaki sposÃ³b bÄ™dÄ… programowane i wykonywane obliczenia w programie. SkÅ‚ada siÄ™ z modelu architekturalnego systemu i jÄ™zyka programowania

Model obliczeniowy komputera na podstawie maszyny Turinga zostaÅ‚ zaproponowany przez Alana Turinga. Jest pierwszym, uniwersalnym modelem obliczeniowym. Opiera siÄ™ na idei, Å¼e komputer jest maszynÄ…, ktÃ³ra jest w stanie wykonywaÄ‡ obliczenia na podstawie serii instrukcji i danych wejÅ›ciowych. 
- SÅ‚uÅ¼y porÃ³wnywaniu wÅ‚asnoÅ›ci rÃ³Å¼nych algorytmÃ³w i programÃ³w pochodzÄ…cych z rÃ³Å¼nych komputerÃ³w
- SkÅ‚ada siÄ™ z nastÄ™pujÄ…cych elementÃ³w:
	- SkoÅ„czony alfabet symboli: a,b,c,â€¦,m
	- SkoÅ„czony zbiÃ³r stanÃ³w: S0,S1,S2,â€¦,Sk
	- NieskoÅ„czona taÅ›ma z polami na zapis symboli
	- GÅ‚owica czytajÄ…co/piszÄ…ca na taÅ›mie, ktÃ³ra moÅ¼e przesuwaÄ‡ siÄ™ o jedno pole w zadanym kierunku
	- Diagram przejÅ›Ä‡ miÄ™dzy stanami â€“ tablica przejÅ›Ä‡ okreÅ›lajÄ…ca nastÄ™pny stan, zapis symbolu pod gÅ‚owicÄ… i kierunek nastÄ™pnego ruchu
- DziaÅ‚anie mechanizmu sterowania:
	- Maszyna w stanie â€iâ€ czyta znak â€zâ€ pod gÅ‚owicÄ…
	- Dla stanu â€iâ€ oraz znaku â€zâ€ maszyna okreÅ›la z tabeli przejÅ›Ä‡:
		- Stan, do ktÃ³rego ma przejÅ›Ä‡
		- Znak, ktÃ³ry ma byÄ‡ wpisany w polu pod gÅ‚owicÄ…
		- Kierunek ruchu gÅ‚owicy o 1 miejsce L â€“ w lewo, R â€“ w prawo
	- GÅ‚owica wpisuje nowy znak i przesuwa siÄ™ w zadanym kierunku

Obydwa te modele odgrywajÄ… kluczowÄ… rolÄ™ w informatyce, poniewaÅ¼ stanowiÄ… podstawy dla projektowania i budowy komputerÃ³w. Model architekturalny komputera wg. von Neumanna umoÅ¼liwia projektowanie i budowÄ™ komputerÃ³w, ktÃ³re sÄ… w stanie przetwarzaÄ‡ dane i instrukcje, natomiast model obliczeniowy komputera na podstawie maszyny Turinga jest niezbÄ™dny do rozwoju teorii algorytmÃ³w.
## Logika boolowska i jej zastosowania w warstwie sprzÄ™towej komputerÃ³w.

Logika boolowska jest dziedzinÄ… matematyki i teorii informacji, ktÃ³ra opiera siÄ™ na dwÃ³ch stanach logicznych: "prawda" i "faÅ‚sz". W logice boolowskiej operacje logiczne (takie jak "i", "lub" i "negacja") sÄ… wykonywane na tych dwÃ³ch stanach.

W warstwie sprzÄ™towej komputerÃ³w, logika boolowska jest uÅ¼ywana do implementacji ukÅ‚adÃ³w logicznych, takich jak bramki AND, OR i NOT. Bramki te sÄ… elementami skÅ‚adowymi procesora i sÄ… wykorzystywane do wykonywania obliczeÅ„ bit po bicie. Logika boolowska jest rÃ³wnieÅ¼ uÅ¼ywana do projektowania i implementacji ukÅ‚adÃ³w scalonych, takich jak pamiÄ™ci i ukÅ‚ady wejÅ›cia-wyjÅ›cia.

OgÃ³lnie rzecz biorÄ…c, logika boolowska jest niezbÄ™dna do projektowania i budowy komputerÃ³w na poziomie sprzÄ™towym, poniewaÅ¼ pozwala na realizacjÄ™ prostych i skutecznych obliczeÅ„ logicznych, ktÃ³re sÄ… niezbÄ™dne dla funkcjonowania komputera.
## Zapis binarny liczb caÅ‚kowitych, zapis zmiennoprzecinkowy liczb rzeczywistych, arytmetyka komputerowa. 

### Liczby caÅ‚kowite
Zapis binarny liczb caÅ‚kowitych to sposÃ³b zapisywania liczb caÅ‚kowitych (czyli bez uÅ‚amkÃ³w) przy uÅ¼yciu tylko dwÃ³ch cyfr binarnych: 0 i 1. KaÅ¼dÄ… liczbÄ™ naturalnÄ… da siÄ™ przedstawiÄ‡ w systemie binarnym i  ma dokÅ‚adnie jednÄ… reprezentacjÄ™. 

Przypisujemy kolejnym pozycjom od prawej do lewej kolejne potÄ™gi dwÃ³jki: â€¦256, 128 ,64, 32, 16, 8, 4, 2, 1.
### Liczby rzeczywiste
1. Nie wystÄ™puje ciÄ…gÅ‚oÅ›Ä‡ liczb â€“ nie kaÅ¼da liczba rzeczywista ma swojÄ… (dokÅ‚adnÄ…) reprezentacjÄ™ 
2. Obliczenia nie sÄ… dokÅ‚adne â€“ zawsze wystÄ™puje bÅ‚Ä…d przybliÅ¼enia. Po kilku tysiÄ…cach/milionach takich dziaÅ‚aÅ„ bÅ‚Ä…d obliczeÅ„ moÅ¼e urosnÄ…Ä‡ do nieakceptowalnych rozmiarÃ³w.
3. Szybkie algorytmy, ktÃ³re wykonujÄ… niewiele dziaÅ‚aÅ„ majÄ… mniejsze prawdopodobieÅ„stwo popeÅ‚nienia bÅ‚Ä™du podczas obliczeÅ„.
4. ZauwaÅ¼one przez Carla Gaussa â€“ zwiÄ™kszanie dokÅ‚adnoÅ›ci nie zawsze prowadzi do polepszenia wyniku koÅ„cowego. Istnieje pewna wartoÅ›Ä‡ graniczna $\Delta x$ po przekroczeniu, ktÃ³rej dokÅ‚adnoÅ›Ä‡ obliczeÅ„ znowu maleje â€“ spowodowane jest to przez bÅ‚Ä…d przybliÅ¼eÅ„.

#### Format staÅ‚oprzecinkowy

Mamy jeden bit na znak, pozostaÅ‚e na liczby. Bity na liczby podzielone sÄ… na **czÄ™Å›Ä‡ caÅ‚kowitÄ…** i **czÄ™Å›Ä‡ uÅ‚amkowÄ…**. Miejsce przecinka binarnego jest umowne (nie ma na nie odrÄ™bnego bitu).  
- czÄ™Å›Ä‡ caÅ‚kowita â€“ potÄ™gi liczby 2 rosnÄ…ce w lewÄ… stronÄ™ od przecinka  
- czÄ™Å›Ä‡ uÅ‚amkowa â€“ ujemne potÄ™gi liczby 2 (1/2, 1/4, 1/8â€¦) malejÄ…ce w prawÄ… stronÄ™ od przecinka  
- przecinek bitowy â€“ miÄ™dzy bitami oznaczajÄ…cymi 1 oraz 0,5  

UÅ‚amki moÅ¼emy reprezentowaÄ‡ jedynie z pewnÄ… dokÅ‚adnoÅ›ciÄ…, zaleÅ¼nÄ… od iloÅ›ci wykorzystanych bitÃ³w  

#### Format zmiennoprzecinkowy

liczba jest przedstawiana w postaci iloczynu:  
$$A=m*p^C$$  
- A â€“ dana liczba,
- m â€“ **mantysa** liczby A,
- p â€“ **podstawa** uÅ¼ywanego systemu (w systemie binarnym to jest 2),
- C â€“ **cecha (wykÅ‚adnik)** uÅ¼ytej potÄ™gi podstawy  
Cecha i mantysa sÄ… przedstawiane osobno w postaci dwÃ³ch staÅ‚oprzecinkowych liczb binarnych w zadanym zapisie binarnym.

Mantysa ma znak i przecinek, moÅ¼e byÄ‡ dodatnia/ujemna oraz caÅ‚kowita/uÅ‚amkowa/mieszana  

Cecha jest zawsze caÅ‚kowita, ale teÅ¼ ma znak i moÅ¼e byÄ‡ dodatnia/ujemna. Cecha peÅ‚ni rolÄ™ skali liczbowej (ona przemieszcza przecinek) z formatu staÅ‚oprzecinkowego  
np. dla 3-bitowej cechy (zakres cech to <-4,3>, bo w tym przykÅ‚adzie jest zapis uzupeÅ‚nienia do 2) i 4-bitowej mantysy:  

| Cecha | Mantysa | Liczba |
| :--: | ---- | ---- |
| 000 | 0100 | $1\over2$ |
| 000 | 0101 | $5\over_{8}$ |
| 010 | 0100 | $2 \frac{1}{2}$ |
### Liczby ujemne 
SÄ… 3 systemy kodowania liczb ujemnych: 
1. Kod znakâ€“moduÅ‚ prosty
2. Kod znakâ€“moduÅ‚ odwrotny (uzupeÅ‚nieniowy do 1)
3. Kod uzupeÅ‚nieniowy (do dwÃ³ch)

#### KOD ZNAKâ€“MODUÅ PROSTY
Wszystkie bity poza najstarszym majÄ… takie samo znaczenie jak w naturalnym kodzie binarnym. WyrÃ³Å¼niony bit w tym zapisie jest bitem znaku. JeÅ¼eli ma on wartoÅ›Ä‡ 0 to dana liczba jest nieujemna, jeÅ¼eli 1, to liczba jest niedodatnia.

>[!warning] Podane kodowanie prowadzi do doÅ›Ä‡ dziwnej sytuacji, Å¼e zero reprezentujemy na 2 sposoby: nieujemne zero (0000) i niedodatnie zero (1000).

### KOD ZNAKâ€“MODUÅ ODWROTNY 
Liczby dodatnie zapisywane sÄ… jak w naturalnym kodzie binarnym, dla liczb ujemnych wszystkie wartoÅ›ci sÄ… zamieniane na przeciwne.

| Znak moduÅ‚ odwrotny | Reprezentacja dziesiÄ™tna | Znak moduÅ‚ odwrotny | Reprezentacja dziesiÄ™tna |
| :--: | ---- | ---- | ---- |
| 0111 | 7 | 1000 | -7 |
| 0110 | 6 | 1001 | -6 |
| 0000 | 0 | 1111 | -0 |

>[!warning] W tym kodowaniu rÃ³wnieÅ¼ wystÄ™pujÄ… dwie reprezentacje 0.

### KOD UZUPEÅNIENIOWY
Dla przypadku liczb 4 bitowych patrzÄ…c od prawej bity majÄ… wartoÅ›ci $âˆ’8, 4, 2, 1$. Z trzech mÅ‚odszych bitÃ³w generujemy wszystkie wartoÅ›ci od 0 do 7, a jeÅ›li wÅ‚Ä…czymy bit âˆ’8, to dodanie do niego tych wartoÅ›ci da nam liczby od âˆ’8 do âˆ’1. W kodzie uzupeÅ‚nieniowym na n bitach da siÄ™ zapisaÄ‡ liczby z zakresu: $âˆ’2 ^{ğ‘›âˆ’1}$ , $2 ^{ğ‘›âˆ’1} â€“ 1$

| Kod uzupeÅ‚nieniowy | Reprezentacja dziesiÄ™tna |
| :--: | ---- |
| 0111 | 7 |
| 0110 | 6 |
| 1010 | -6 |
| 1001 | -7 |
| 1000 | -8 |

Zapis zmiennoprzecinkowy liczb rzeczywistych to sposÃ³b zapisywania liczb rzeczywistych (czyli z uÅ‚amkami) w komputerach. W tym zapisie liczba jest dzielona na czÄ™Å›Ä‡ caÅ‚kowitÄ… i uÅ‚amkowÄ…, a kaÅ¼da z tych czÄ™Å›ci jest zapisywana za pomocÄ… zapisu binarnego.
Arytmetyka komputerowa to dziedzina informatyki, ktÃ³ra zajmuje siÄ™ realizacjÄ… obliczeÅ„ matematycznych na komputerach. W arytmetyce komputerowej omawia siÄ™ m.in. sposoby obliczania wartoÅ›ci funkcji, rozwiÄ…zywania rÃ³wnaÅ„, a takÅ¼e przeprowadzania obliczeÅ„ zmiennoprzecinkowych i liczb caÅ‚kowitych. Celem arytmetyki komputerowej jest zapewnienie dokÅ‚adnoÅ›ci i wydajnoÅ›ci obliczeÅ„ matematycznych w komputerach.

## Miary efektywnoÅ›ci obliczeniowej procesorÃ³w, pojemnoÅ›ci pamiÄ™ci komputerowej oraz wydajnoÅ›ci systemÃ³w obliczeniowych.

O efektywnoÅ›ci dziaÅ‚ania systemu komputerowego decydujÄ… zarÃ³wno elementy odpowiedzialne ze szybkÄ… realizacjÄ™ obliczeÅ„ numerycznych (zegar procesora, wielkoÅ›Ä‡ i organizacja pamiÄ™ci notatnikowej, szybkoÅ›Ä‡ dziaÅ‚ania magistrali wewnÄ™trznych itp.), jak i elementy odpowiadajÄ…ce za szybkoÅ›Ä‡ i niezawodnoÅ›Ä‡ wymiany danych. Aby byÄ‡ pewnym dostÄ™pnoÅ›ci poprawnych danych w maksymalnym stopniu pamiÄ™ci masowe muszÄ… zapewniaÄ‡ nastÄ™pujÄ…ce wymagania:
1. szybki dostÄ™p do danych
2. duÅ¼a pojemnoÅ›Ä‡
4. skalowalnoÅ›Ä‡
5. wysokie bezpieczeÅ„stwo przechowywanych informacji
6. odpornoÅ›Ä‡ na zdarzenia losowe
7. niski koszt konstrukcji i eksploatacji systemÃ³w pamiÄ™ciowych

Miary efektywnoÅ›ci obliczeniowej procesorÃ³w to wskaÅºniki opisujÄ…ce, jak szybko procesor jest w stanie wykonaÄ‡ okreÅ›lone zadania. Najbardziej popularne miary efektywnoÅ›ci obliczeniowej to:
- CzÄ™stotliwoÅ›Ä‡ zegara â€“ decyduje o szybkoÅ›ci wykonywania operacji na komputerze  SzybkoÅ›Ä‡ obliczeÅ„ mierzymy w **_(to sÄ… te miary wydajnoÅ›ci systemÃ³w obliczeniowych)_**:  
	- **MIPS (Millions of Instructions per Second)** â€“  okreÅ›la liczbÄ™ operacji (staÅ‚oprzecinkowych) jakie procesor jest w stanie wykonaÄ‡ w czasie sekundy.
	- **MFLOPS (Millions of Floating Point Operations per Second)** â€“ mierzy liczbÄ™ operacji zmiennoprzecinkowych, jakie procesor jest w stanie wykonaÄ‡ w ciÄ…gu jednej sekundy.
	- MHz (Megahertz) lub GHz (Gigahertz) - okreÅ›lajÄ… czÄ™stotliwoÅ›Ä‡ taktowania procesora, czyli liczbÄ™ cykli pracy na sekundÄ™.
	- IPC (Instructions Per Clock) 

PojemnoÅ›Ä‡ pamiÄ™ci komputerowej jest mierzona w bajtach (B) lub kilobajtach (KB), megabajtach (MB), gigabajtach (GB) i terabajtach (TB). Miarami wydajnoÅ›ci systemÃ³w sÄ… pamiÄ™Ä‡ i czas.

Na wydajnoÅ›Ä‡ procesora ma teÅ¼ wpÅ‚yw:
- Liczba i cechy blokÃ³w wykonawczych â€“ liczba jednostek wykonujÄ…cych operacje okreÅ›lone w instrukcjach programu w jÄ™zyku wewnÄ™trznym oraz ich cechy funkcjonalne
- Struktura i parametry pamiÄ™ci â€“ liczba poziomÃ³w pamiÄ™ci (w tym liczba poziomÃ³w pamiÄ™ci podrÄ™cznej). Organizacja zapisywanej informacji, pojemnoÅ›ci
- Cechy i parametry listy rozkazÃ³w â€“ typy i format instrukcji jÄ™zyka wewnÄ™trznego, dostÄ™pne tryby adresowania, metoda realizacji instrukcji wejÅ›cia/wyjÅ›cia  

**_Trzy kolejne okreÅ›lajÄ… wydajnoÅ›Ä‡ obliczeniowÄ… procesora:_**
- **Liczba i rozmiary rejestrÃ³w danych**
- **Liczba i rozmiary rejestrÃ³w adresowych**
- **SzerokoÅ›Ä‡ szyn danych i adresÃ³w**
## Prawo Mooreâ€™a i implikacje z niego wynikajÄ…ce w kontekÅ›cie rozwoju sprzÄ™tu komputerowego.

Prawo Moore'a to prawo, ktÃ³re stwierdza, Å¼e liczba tranzystorÃ³w na jednostkÄ™ powierzchni ukÅ‚adu scalonego podwaja siÄ™ co okoÅ‚o 1,2-1,3 roku. To prawo zostaÅ‚o opublikowane po raz pierwszy przez Gordona Moore'a w 1965 roku i od tego czasu staÅ‚o siÄ™ jednym z najbardziej znanych i niezawodnych trendÃ³w w historii rozwoju elektroniki.

Implikacje zwiÄ…zane z Prawem Moore'a sÄ… znaczne i dotyczÄ… nie tylko samego rozwoju sprzÄ™tu komputerowego, ale takÅ¼e szeroko pojÄ™tej technologii informacyjnej. Oto kilka kluczowych implikacji:
- **PostÄ™p technologiczny**: DziÄ™ki ciÄ…gÅ‚emu wzrostowi liczby tranzystorÃ³w na jednostkÄ™ powierzchni, sprzÄ™t komputerowy staje siÄ™ coraz bardziej zaawansowany i wydajny, co przyczynia siÄ™ do jego rozwoju.
- **Zmniejszanie cen**: ZwiÄ™kszenie liczby tranzystorÃ³w na jednostkÄ™ powierzchni ukÅ‚adu scalonego prowadzi do niÅ¼szych cen i dostÄ™pnoÅ›ci komputerÃ³w dla szerokiej publicznoÅ›ci.
- **Nowe aplikacje**: ZwiÄ™kszona wydajnoÅ›Ä‡ sprzÄ™tu komputerowego pozwala na stworzenie nowych aplikacji i usÅ‚ug, takich jak sztuczna inteligencja czy chmura obliczeniowa.
- **Zmiana sposobu Å¼ycia**: Prawo Moore'a i jego implikacje sprawiajÄ…, Å¼e technologia informacyjna jest coraz bardziej dostÄ™pna i powszechna, co zmienia sposÃ³b, w jaki ludzie Å¼yjÄ…, pracujÄ… i komunikujÄ… siÄ™.