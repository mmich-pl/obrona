## CaÅ‚ka nieoznaczona, oznaczona, zastosowanie i techniki obliczania.

>[!info] Pochodna funkcji
>Nieformalnie miara szybkoÅ›ciÂ funkcji, czyli tempa zmian jej wartoÅ›ci wzglÄ™dem zmian jejÂ argumentÃ³w.
>
>NiechÂ $y=f(x)$Â bÄ™dzie funkcjÄ… rzeczywistÄ… zmiennej rzeczywistejÂ $x$ okreÅ›lonÄ… wÂ otoczeniuÂ punktuÂ $x_{0}$.Â **PochodnÄ… funkcji**Â $f(x)$Â w punkcieÂ $x_0$Â nazywamyÂ granicÄ™ (o ile istnieje):
>$$\large \lim_{  \Delta x \to \infty }  {{f(x_{0}+\Delta x) - f(x_{0})}\over {\Delta x}}$$
>jeÅ¼eli przyjmiemy, Å¼e $x=x_{0}+\Delta x$, to pochodnÄ… w punkcie $x_{0}$ moÅ¼na zapisaÄ‡ jako:
>$$\large \lim_{  x \to x_{0} }  {{f(x) - f(x_{0})}\over { x- x_{0}}}$$
>
>WÅ‚asnoÅ›ci pochodnej funkcji:
>- iloczyn pochodnej przez staÅ‚Ä…: $(af)'(x)=af'(x)$
>- pochodna sumy funkcji $(f+g)'(x)=f'(x)+g'(x)$
>- pochodna iloczynu funkcji $(fg)'(x)=f'(x)g(x)+f(x)g'(x)$
>- pochodnaÂ zÅ‚oÅ¼enia funkcji $f'(x)=h'{\big (}g(x){\big )}g'(x),\quad {\text{ dla }}\quad f(x)=h(g(x))$
>- pochodna ilorazu funkcji (_reguÅ‚a ilorazu_) $\left({\tfrac {f(x)}{g(x)}}\right)'={\frac {f'(x)g(x)-f(x)g'(x)}{g^{2}(x)}},\quad {\text{ o ile }}\quad g(x)\neq 0.$

Funkcja $F(X)$Â jestÂ **funkcjÄ… pierwotnÄ…**Â funkcji $f(x)$Â w przedzialeÂ $(a;b)$, jeÅ¼eliÂ $F'(x) = f(x)$Â dla kaÅ¼degoÂ $x$Â z tegoÂ przedziaÅ‚u.
FunkcjaÂ $f(x)=x^3$Â to funkcja pierwotna w stosunku do funkcjiÂ $3x^2$Â w zbiorze liczb rzeczywistych, poniewaÅ¼Â $f'(x^3)=3x^2$.

### CaÅ‚ka nieoznaczona
**CaÅ‚kÄ… nieoznaczonÄ…**Â funkcjiÂ $f(x)$Â nazywamy wyraÅ¼enieÂ $F(x)+C$. CaÅ‚kÄ™ funkcji $f(x)$ oznaczamy nastÄ™pujÄ…co: $\int_{}^{} f(x) \,dx = F(x) + C$.

$$\int  x^2 \, dx = \frac{x^{2+1}}{2+1} + C = \frac{x^3}{3}+C $$

### CaÅ‚ka oznaczona
JeÅ¼eli $F(x)$ jest funkcjÄ… pierwotnÄ… funkcji $f(x)$ ciÄ…gÅ‚ej w danym przedziale $[x_{1}, x_{2}]$, to rÃ³Å¼nicÄ™ funkcji pierwotnych $F(x_{1})$ i $F(x_{2})$ nazywamy **caÅ‚kÄ… oznaczonÄ…** dla funkcji $f$ od $x_{1}$ do $x_2$.

$$ \int ^{x_{2}}_{x_{1}} f(x) \, dx = F(x_{2}) - F(x_{1})$$

$$\int ^{3}_{1} x^2\, dx = \left[ \frac{x^3}{3} \right]^{3}_{1} = 9 - \frac{1}{3} = \frac{26}{3}$$
### CaÅ‚kowanie przez podstawienie, czyli zamianÄ™ zmiennej
CaÅ‚kowanie przez podstawienie stosujemy, gdy wÅ›rÃ³d funkcji podcaÅ‚kowej potrafimy wyodrÄ™bniÄ‡ pewnÄ… funkcjÄ™ i jej pochodnÄ….
$$\int x \log x \,dx =
\left|
  \begin{alignedat}{2}
  u       &= \log x             \quad & \,dv &= x \,dx \\
  \,du &= \frac{1}{x} x \,dx \quad & v &= \frac{x^2}{2}
  \end{alignedat}\,
\right|
=
\frac{x^2}{2}\log x - \int \frac{x^2}{2}\frac{1}{x} \,dx
$$

### CaÅ‚kowanie przez czÄ™Å›ci
JeÅ¼eli funkcje $u$ i $v$ majÄ… na pewnym przedziale $P$ ciÄ…gÅ‚e pochodne $u'$ i $v'$, to $\large \int f'(x) g(x) \, dx = f(x)g(x) - \int f(x) g'(x) \, dx$ na tym przedziale.

$$\begin{align}
\int x \ln x \,dx &=
\left|
  \begin{alignedat}{2}
  g(x)    &= \ln x    \quad & f'(x) &= x \\
  \,g'(x) &= \frac{1}{x} \quad & f(x)&= \frac{x^2}{2}
  \end{alignedat}\,
\right|\\
&=
\frac{x^2}{2}\ln x - \int \frac{x^2}{2}\frac{1}{x} \,dx \\&= \frac{1}{2}x^2\ln x - \frac{1}{2}\int x \, dx \\&= \frac{1}{2}x^2x\ln x-\frac{1}{4}x^2+c
\end{align}$$

### Metoda prostokÄ…tÃ³w
Dzielimy dany przedziaÅ‚ $**[a, b]**$ na $n$ odcinkÃ³w. W kaÅ¼dym odcinku wyliczamy wartoÅ›ci funkcji dla argumentÃ³w z poczÄ…tku i koÅ„ca odcinka. UÅ›redniony wynik to wysokoÅ›Ä‡ prostokÄ…ta o podstawie rÃ³wnej dÅ‚ugoÅ›ci odcinka.
### Metoda trapezÃ³w
PrzedziaÅ‚ caÅ‚kowania dzielimy na $n$ rÃ³wnych odcinkÃ³w. NastÄ™pnie obliczamy wartoÅ›ci funkcji $f(x)$ w punktach $a$ i $b$ oraz w punktach, ktÃ³re sÄ… koÅ„cami dwÃ³ch odcinkÃ³w. Wtedy caÅ‚kÄ™ obliczamy nastÄ™pujÄ…co:
$$\int ^a_{b} f(x) \, dx \approx h\left( \frac{f(a)}{2} + \sum_{i=2}^n f(x_{i}) + \frac{f(b)}{2} \right)$$
### Zastosowanie caÅ‚ek
- obliczanie pÃ³l figur pÅ‚askich
- obliczanie dÅ‚ugoÅ›ci Å‚uku krzywej
- obliczanie pola powierzchni bryÅ‚y obrotowej
- obliczanie pracy wykonywanej przez zmiennÄ… siÅ‚Ä™
## Wielomian i szereg Taylora funkcji rzeczywistej. 
**Szereg Taylora to wielomian, ktÃ³ry przybliÅ¼a funkcjÄ™** w bliskim otoczeniu. PrzybliÅ¼enie to **dotyczy dowolnego punktu** $x$, a nie tylko jednego konkretnego i wyrÃ³Å¼nionego punktu. WzÃ³r Taylora jest bardzo ogÃ³lny i **opisuje funkcjÄ™ jako caÅ‚oÅ›Ä‡**.

**Definicja**
JeÅ›li funkcja $f$ ma w punkcie $x_{0}$ pochodnÄ… rzÄ™du $k$, to **wielomianem Taylora rzÄ™du $k$** funkcji $f$ w $x_0$ nazywamy wielomian

$$\begin{align}
T_{x_{0}} &= f(x_{0}) + \frac{f'(x_{0})}{1!}(x-x_{0}) + \dots + \frac{f^{(k)}(x_{0})}{k!}(x-x_{0})^k \\ \\
&= f(x_{0}) + \sum^{k-1}_{i=1}\frac{f^{(i)}(x_{0})}{i!}(x-x_{0})^i
\end{align}
$$
W szczegÃ³lnym przypadku gdy $x_{0} =0$ wielomian
$$T_{0}(x) = f(0)+\frac{f'(0)}{1!}x+\dots+\frac{f^{(k)}(0)}{k!}x^k$$
nazywamy **wielomianem MacLaurina rzÄ™du $k$ funkcji $f$.**

**WzÃ³r Taylora z resztÄ… w postaci Lagrange'a**

JeÅ›li funkcja $f$
1. ma ciÄ…gÅ‚Ä… pochodnÄ… rzÄ™du _n-1_ w przedziale $[x_{0}, x]$
2. ma pochodnÄ… rzÄ™du n w przedziale otwartym $(x_{0}, x)$
to istnieje punkt $c \in (x_{0},x)$, taki Å¼e:
$$f(x)= T_{x_{0}}(x) + R_{n}(x)= f(x_{0}) + \sum^{k-1}_{i=1}\frac{f^{(i)}(x_{0})}{i!}(x-x_{0})^i + R_{n}(x)$$
gdzie $\large R_{n}=\frac{f^{(n)}(c)}{n!}(xâˆ’x_{0})^n$ dla pewnego $c \in (x_{0}, x)$.

PomijajÄ…c we wzorze Taylora resztÄ™ $R_{n}(x)$ otrzymujemy w otoczeniu punktu $x_{0}$ przybliÅ¼enie funkcji $f$ wielomianem stopnia (co najwyÅ¼ej) $n-1$. n-ta reszta z wzoru Taylora to po prostu liczba wskazujÄ…ca na _bÅ‚Ä…d przybliÅ¼enia liczby $f(x)$ liczbÄ…_ $T_{x_{0}}(x)$
## UkÅ‚ady rÃ³wnaÅ„ liniowych: rÃ³Å¼ne metody rozwiÄ…zywania, liczba rozwiÄ…zaÅ„. 

### Wzory Cramera
MoÅ¼emy ich uÅ¼yÄ‡ gdy:
- liczba rÃ³wnaÅ„ jest rÃ³wna liczbie niewiadomych
- wyznacznik gÅ‚Ã³wny macierzy jest rÃ³Å¼ny od 0
	- W przeciwnym przypadku, gdy $det ( a 1 , â€¦ , a n ) = 0$ ukÅ‚ad jest
		- _sprzeczny_ (nie ma rozwiÄ…zaÅ„), gdy choÄ‡ jeden wyznacznik we wzorach Cramera zawierajÄ…cy jest rÃ³Å¼ny od zera;
		- _nieoznaczony_ (ma wiÄ™cej niÅ¼ jedno rozwiÄ…zanie) lub sprzeczny, gdy wszystkie wyznaczniki we wzorach Cramera zawierajÄ…ce sÄ… rÃ³wne zeru.

$W$ - wyznacznik gÅ‚Ã³wny
$W_{x}, W_{y}, W_{z}, \dots$ - wyznaczniki, w ktÃ³rych wspÃ³Å‚czynniki przy $x,y,z,\dots$ zastÄ™pujemy wyrazami wolnymi

$$
\begin{align*}
&\begin{cases}
2x+5y+3z = 5  \\[.75em]
4x+2y+5z = 4   \\[.75em]
3x+8y+4z = 9   \\[.75em]
\end{cases}   \\[1.25em]


W = &\begin{bmatrix} 
 2 & 5 & 3\\
 4 & 2 & 5\\
 3 & 8 & 6 \\
\end{bmatrix} = 9 \\[1.25em]

W_{x} = \begin{bmatrix} 
 5 & 5 & 3\\
 4 & 2 & 5\\
 9 & 8 & 6 \\
\end{bmatrix} = 27 \: \: \: \: \: \: \: \:

W_{y} = &\begin{bmatrix} 
 2 & 5 & 3\\
 4 & 4 & 5\\
 3 & 9 & 6 \\
\end{bmatrix} = 9 \: \: \: \: \: \: \: \:

W_{z} = \begin{bmatrix} 
 2 & 5 & 5\\
 4 & 2 & 4\\
 3 & 8 & 9 \\
\end{bmatrix} = -18\\[1.25em]

&\begin{cases}
x = \frac{W_{x}}{W} = \frac{27}{9} = 3  \\[.75em]
y = \frac{W_{y}}{W} = \frac{9}{9} = 1  \\[.75em]
z = \frac{W_{z}}{W} = \frac{-18}{9} = -2  \\[.75em]
\end{cases}   \\[1.25em]
\end{align*} 
$$

### Metoda Gaussa
>[!info] RzÄ…d macierzy
>ChcÄ…c obliczyÄ‡ rzÄ…d macierzy musimy znaleÅºÄ‡ najwiÄ™kszÄ… macierz, ktÃ³rej wyznacznik jest rÃ³Å¼ny od zera, wielkoÅ›Ä‡ tej niezerowej macierzy bÄ™dzie szukanÄ… wartoÅ›ciÄ…, czyli jeÅ›li najwiÄ™kszÄ… macierzÄ…, ktÃ³rej wyznacznik jest rÃ³Å¼ny od zera jest macierz 3x3 to rzÄ…d macierzy jest rÃ³wny 3.

#### Twierdzenie Kroneckera-Capellego
To twierdzenie jest nam pomocne przy okreÅ›laniu **liczby rozwiÄ…zaÅ„** ukÅ‚adu rÃ³wnaÅ„ liniowych. W przeciwieÅ„stwie do Twierdzenia Cramera, tutaj ukÅ‚ad rÃ³wnaÅ„ moÅ¼e byÄ‡ dowolny (tzn. liczba rÃ³wnaÅ„ i niewiadomych nie muszÄ… byÄ‡ sobie rÃ³wne).

$$
\begin{align*}
&\begin{cases}
x+2y-z = 5  \\[.75em]
3x+4y+z = 9   \\[.75em]
2x-2y+3z = 1   \\[.75em]
\end{cases}   \\[1.25em]
&A = \left[
\begin{array}{ccc}
1 & 2 & -1  \\
3 & 4 & 1  \\
2 & -2 & 3  \\
\end{array}
\right]\\[1.2em]
&U = \left[
\begin{array}{ccc|c}
1 & 2 & -1 & 5 \\
3 & 4 & 1 & 9 \\
2 & -2 & 3 & -1 \\
\end{array}
\right]
\end{align*}
$$
 Warunkiem koniecznym i wystarczajÄ…cym na to, aby ukÅ‚ad miaÅ‚ rozwiÄ…zanie jest rÃ³wnoÅ›Ä‡ rzÄ™dÃ³w macierzy gÅ‚Ã³wnej $A$ i macierzy uzupeÅ‚nionej $U$ czyli: $r(A)=r(U)$.
- JeÅ›li $r(A)=r(U)=n$ , gdzie $n$ jest liczba niewiadomych, to ukÅ‚ad ma dokÅ‚adnie jedno rozwiÄ…zanie. 
- JeÅ›li $r(A)=r(U)<n$, to ukÅ‚ad ma nieskoÅ„czenie wiele rozwiÄ…zaÅ„ zaleÅ¼nych od $n-r$ parametrÃ³w.
- JeÅ›li $r(A) \neq r(U)$, to ukÅ‚ad nie ma rozwiÄ…zaÅ„ i nazywa siÄ™ ukÅ‚adem sprzecznym. 
---
1. UkÅ‚ad rÃ³wnaÅ„ jest zapisywany pod postaciÄ… macierzy wspÃ³Å‚czynnikÃ³w
2. NastÄ™puje przeksztaÅ‚cenie wierszy za pomocÄ… operacji elementarnych
	- dodanie lub odjÄ™cie do dowolnego wiersza pomnoÅ¼onego przez liczbÄ™ lub w niezmienionej postaci
	- pomnoÅ¼enie dowolnego wiersza przez liczbÄ™ innÄ… niÅ¼ 0
	- zamiana miejscami dwÃ³ch wierszy
3. PrzeksztaÅ‚cenia majÄ… na celu otrzymanie macierzy schodkowej czyli speÅ‚niajÄ…cej warunki
	- na schodkach sÄ… tylko liczby rÃ³Å¼ne od 0
	- pod schodkami sÄ… tylko 0
4. Z otrzymanej macierzy ukÅ‚adane sÄ… rozwiÄ…zania rÃ³wnaÅ„ zaczynajÄ…c od ostatniego wiersza.
$$
\begin{align*}
&\begin{cases}
x+2y-z = 5  \\[.75em]
3x+4y+z = 9   \\[.75em]
2x-2y+3z = 1   \\[.75em]
\end{cases}   \\[1.25em]


&\left[
\begin{array}{ccc|c}
1 & 2 & -1 & 5 \\
3 & 4 & 1 & 9 \\
2 & -2 & 3 & -1 \\
\end{array}
\right]

\begin{array}{c}
~\\
-3w_{1} \\
-2w_{1} \\
\end{array} \longrightarrow

\left[
\begin{array}{ccc|c}
1 & 2 & -1 & 5 \\
0 & -2 & 4 & -6 \\
0 & -6 & 5 & -11 \\
\end{array}
\right]

\begin{array}{c}
~\\
~ \\
* -1 \\
\end{array} \longrightarrow \\[1.25em]

&\left[
\begin{array}{ccc|c}
1 & 2 & -1 & 5 \\
0 & -2 & 4 & -6 \\
0 & 6 & -5 & 11 \\
\end{array}
\right]

\begin{array}{c}
~\\
~ \\
+3w_{2} \\
\end{array} \longrightarrow

\left[
\begin{array}{ccc|c}
1 & 2 & -1 & 5 \\
0 & -2 & 4 & -6 \\
0 & 0 & 7 & -7 \\
\end{array}
\right]\\[1.25em]



&\begin{cases}
x+2y-z=5 \Rightarrow x=2 \\[.75em]
-2y + 4z = -6 \Rightarrow y = 1 \\[.75em]
7z = -7 \Rightarrow z = -1 \\[.75em]
\end{cases} 
\end{align*} 
$$
## WartoÅ›ci wÅ‚asne macierzy i ich zastosowanie w informatyce.

>[!info] Endomorfizm liniowy â€“ przeksztaÅ‚cenie liniowe przestrzeni $V$ zgodnie ze wzorem $f: V \rightarrow V$ (przejÅ›cie w takÄ… samÄ… przestrzeÅ„).  Macierz endomorfizmu jest macierzÄ… kwadratowÄ…  

$v \inÂ V$ â€“ **wektor wÅ‚asny** endomorfizmu $f$, jeÅ›li $v \neq 0$ oraz istnieje $\lambda \inÂ R$ takie, Å¼e $f(v) = \lambda*v$ 
W tym rÃ³wnaniu, $\lambda$ â€“ **wartoÅ›Ä‡ wÅ‚asna** endomorfizmu $f$.

PrzykÅ‚ad endomorfizmu: $f: R^3 \rightarrow R^3$
Dla $f([1,1,1]) = [5,5,5] = 5*[1,1,1]$ -> wektor wÅ‚asny to $[1,1,1]$, a wartoÅ›Ä‡ wÅ‚asna to $5$.

Zastosowanie wartoÅ›ci wÅ‚asnych w informatyce:
- Rankingowanie stron internetowych w wyszukiwarce Google (algorytm PageRank â€“ linki miÄ™dzy stronami i wagi tych linkÃ³w sÄ… zapisane w macierzach, wartoÅ›Ä‡ wÅ‚asna przyspiesza liczenie tych wag)
- PCA (principal component analysis â€“ do zmniejszania wymiarowoÅ›ci danych uÅ¼ywanych przy uczeniu maszynowym, przy zmniejszaniu wymiarÃ³w, tworzona jest macierz kowariancji zmiennych (powinienem to opisaÄ‡ w zagadnieniu 9 lub 10)Â  po znalezieniu jej wektora wÅ‚asnego, wektor ten wyznacza kierunek hiperpÅ‚aszczyzny, na ktÃ³rÄ… rzutujemy atrybuty danych)
- Algorytm partycji grafÃ³w (dzielenie grafÃ³w na kilka mniejszych, ktÃ³re sÄ… ze sobÄ… poÅ‚Ä…czone pojedynczymi przejÅ›ciami, druga najmniejsza wartoÅ›Ä‡ wÅ‚asna w macierzy przejÅ›Ä‡ daje nam dolnÄ… granicÄ™ optymalnego przeciÄ™cia grafu)

## Grafy i ich typy, metody reprezentacji grafÃ³w. 
**Graf**Â â€“ Â struktura matematyczna sÅ‚uÅ¼Ä…ca do przedstawiania i badania relacji miÄ™dzy obiektami. W uproszczeniu graf to zbiÃ³rÂ wierzchoÅ‚kÃ³w, ktÃ³re mogÄ… byÄ‡ poÅ‚Ä…czoneÂ krawÄ™dziamiÂ w taki sposÃ³b, Å¼e kaÅ¼da krawÄ™dÅº koÅ„czy siÄ™ i zaczyna w ktÃ³rymÅ› z wierzchoÅ‚kÃ³w.

WierzchoÅ‚ki grafu mogÄ… byÄ‡ numerowane i czasem stanowiÄ… reprezentacjÄ™ jakichÅ› obiektÃ³w, natomiast krawÄ™dzie mogÄ… wÃ³wczas obrazowaÄ‡ relacje miÄ™dzy takimi obiektami. WierzchoÅ‚ki naleÅ¼Ä…ce do krawÄ™dzi nazywane sÄ… jej koÅ„cami.

**Droga**(Å›cieÅ¼ka): naprzemiennych wierzchoÅ‚kÃ³w i krawÄ™dzi $v_{0}, e_{0}, v_{1}, \dots v_{k-1}, e_{k}, v_{k}$, taki, Å¼e krawÄ™dÅº $e_{k}$ zawsze Å‚Ä…czy wierzchoÅ‚ki $v_{k-1}$ i $v_{k}$.

**Cykl**Â jest Å›cieÅ¼kÄ…, ktÃ³ra rozpoczyna siÄ™ i koÅ„czy w tym samym wierzchoÅ‚ku. Aby stwierdziÄ‡, czy graf zawiera jakiÅ› cykl, przechodzimy go algorytmem DFS. JeÅ›li w trakcie przechodzenia natrafimy na wierzchoÅ‚ek juÅ¼ odwiedzony, a nie jest to wierzchoÅ‚ek, z ktÃ³rego przyszliÅ›my, to graf jest cykliczny.
### Rodzaje grafÃ³w
#### Graf nieskierowany  
**Graf nieskierowany**Â  to zbiÃ³r wierzchoÅ‚kÃ³w i krawÄ™dzi, wierzchoÅ‚ki naleÅ¼Ä…ce do krawÄ™dzi sÄ…  jej koÅ„cami.
```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,4) {C};
    \node (D) at (2.5,1) {D};
    \node (E) at (2.5,-3) {E};
    \node (F) at (5,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path (A) edge (B);
    \path (B) edge (C);
    \path (A) edge (D);
    \path (D) edge (C);
    \path (A) edge (E);
    \path (D) edge (E);
    \path (D) edge (F);
    \path (C) edge (F);
    \path (E) edge (F); 
\end{scope}
\end{tikzpicture}
\end{document}
```

#### Graf skierowany  
W grafieÂ **skierowanym**Â krawÄ™dzie oznaczane strzaÅ‚kami pokazujÄ… nam konkretny kierunek, w ktÃ³rym moÅ¼emy poruszaÄ‡ siÄ™ po grafie.

```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,4) {C};
    \node (D) at (2.5,1) {D};
    \node (E) at (2.5,-3) {E};
    \node (F) at (5,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path [->] (A) edge (B);
    \path [->] (B) edge (D);
    \path [->] (B) edge (C);
    \path [->] (A) edge (D);
    \path [->] (D) edge (C);
    \path [->] (A) edge (E);
    \path [->] (D) edge (E);
    \path [->] (D) edge (F);
    \path [->] (C) edge (F);
    \path [->] (E) edge (F); 
\end{scope}
\end{tikzpicture}
\end{document}
```

#### Graf spÃ³jny i niespÃ³jny
NastÄ™pnie spÃ³jnoÅ›Ä‡ - graf jestÂ **spÃ³jny**Â jeÅ¼eli dla kaÅ¼dej pary wierzchoÅ‚kÃ³w istnieje Å›cieÅ¼ka, ktÃ³ra je Å‚Ä…czy.
```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,4) {C};
    \node (D) at (2.5,1) {D};
    \node (E) at (2.5,-3) {E};
    \node (F) at (5,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path (A) edge (B);
    \path (D) edge (E);
    \path (D) edge (F);
    \path (E) edge (F); 
\end{scope}
\end{tikzpicture}
\end{document}
```

#### Graf peÅ‚ny
GrafÂ **peÅ‚ny**Â - to taki graf prosty, w ktÃ³rym dla kaÅ¼dej pary wierzchoÅ‚kÃ³w istnieje krawÄ™dÅº je Å‚Ä…czÄ…ca.

```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,4) {C};
    \node (D) at (3,1) {D};    
    \node (E) at (2.5,-3) {E};
    \node (F) at (5,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path (A) edge (B);
    \path (A) edge (C);
    \path (A) edge (D);
    \path (A) edge (E);
    \path (A) edge (F);
    \path (B) edge (C);
    \path (B) edge (D);
    \path (B) edge (E);
    \path (B) edge (F);
    \path (C) edge (D);
    \path (C) edge (E);
    \path (C) edge (F);
    \path (D) edge (E);
    \path (D) edge (F);
    \path (E) edge (F);
   
\end{scope}
\end{tikzpicture}
\end{document}
```
#### Graf dwudzielny  
ZbiÃ³r wierzchoÅ‚kÃ³w **grafu dwudzielnego** moÅ¼na podzieliÄ‡ na dwa rozÅ‚Ä…czne zbiory tak, Å¼e krawÄ™dzie nie Å‚Ä…czÄ… wierzchoÅ‚kÃ³w tego samego zbioru. JeÅ›li pomiÄ™dzy wszystkimi parami wierzchoÅ‚kÃ³w naleÅ¼Ä…cych do rÃ³Å¼nych zbiorÃ³w istnieje krawÄ™dÅº to taki graf nazywamy grafemÂ **peÅ‚nymÂ dwudzielnym**.

```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,1.5) {B};
    \node (C) at (0,-1.5) {C};
    \node (D) at (3,1) {D};    
    \node (E) at (3,4.5) {E};
    \node (F) at (3,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path (A) edge (D);
    \path (B) edge (E);
    \path (B) edge (F);
    \path (A) edge (F);
    \path (C) edge (D);
   
\end{scope}
\end{tikzpicture}
\end{document}
```

#### Graf z wagami (graf waÅ¼ony)
To taki graf, w ktÃ³rym kaÅ¼dej krawÄ™dzi przypisana jest pewna wartoÅ›Ä‡ liczbowa. WartoÅ›Ä‡ ta moÅ¼e oznaczaÄ‡ np. dÅ‚ugoÅ›Ä‡ krawÄ™dzi lub jej przepustowoÅ›Ä‡.
```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,4) {C};
    \node (D) at (2.5,1) {D};
    \node (E) at (2.5,-3) {E};
    \node (F) at (5,3) {F} ;
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
    \path [->] (A) edge node {$5$} (B);
    \path [->] (B) edge node {$3$} (C);
    \path [->] (A) edge node {$4$} (D);
    \path [->] (D) edge node {$3$} (C);
    \path [->] (A) edge node {$3$} (E);
    \path [->] (D) edge node {$3$} (E);
    \path [->] (D) edge node {$3$} (F);
    \path [->] (C) edge node {$5$} (F);
    \path [->] (E) edge node {$8$} (F); 
\end{scope}
\end{tikzpicture}
\end{document}
```

### Sposoby prezentacji
#### Lista krawÄ™dzi
Lista krawÄ™dzi polega na tym, Å¼e mamy listÄ™ zawierajÄ…cÄ… definicjÄ™ krawÄ™dzi. Definicja krawÄ™dzi w najprostszej postaci to para wierzchoÅ‚kÃ³w. Dla poniÅ¼szego grafu wyglÄ…daÅ‚oby to nastÄ™pujÄ…co: [(A, B), (C,A), (A,D), (B,C)].

```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,2) {C};
    \node (D) at (2.5,-2) {D};
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
 \path [->] (A) edge (B);
 \path [->] (A) edge (D);
 \path [->] (B) edge (C);
 \path [->] (C) edge (A);
\end{scope}
\end{tikzpicture}
\end{document}
```

#### Lista sÄ…siedztwa
Lista sÄ…siedztwa jest listÄ… list. Kolejne indeksy w tej liÅ›cie odpowiadajÄ… wierzchoÅ‚kom grafu, a pod nimi znajdziemy listÄ™ wierzchoÅ‚kÃ³w, do ktÃ³rych moÅ¼emy z niego dostaÄ‡ siÄ™ bezpoÅ›rednio. 

Taka struktura sugeruje uÅ¼ycie do grafu skierowanego, ale moÅ¼emy teÅ¼ zastosowaÄ‡ jÄ… w grafach nieskierowanych, tylko trzeba bÄ™dzie powieliÄ‡ krawÄ™dÅº (Å¼eby z obu wierzchoÅ‚kÃ³w daÅ‚o siÄ™ dojÅ›Ä‡ do siebie nawzajem).

Dla poniÅ¼szego grafu wyglÄ…daÅ‚oby to nastÄ™pujÄ…co: [A:[B, D], B:[C], C:[A], D:[]].
```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,2) {C};
    \node (D) at (2.5,-2) {D};
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
 \path [->] (A) edge (B);
 \path [->] (A) edge (D);
 \path [->] (B) edge (C);
 \path [->] (C) edge (A);
\end{scope}
\end{tikzpicture}
\end{document}
```


#### Macierz sÄ…siedztwa
Jest to macierz o wymiarachÂ iloÅ›Ä‡WÄ™zÅ‚Ã³w$\times$iloÅ›Ä‡WÄ™zÅ‚Ã³w, w ktÃ³rej wartoÅ›ci wskazujÄ…, czy wierzchoÅ‚ki sÄ… ze sobÄ… poÅ‚Ä…czone, czy teÅ¼ nie. W grafach niewaÅ¼onych zwykle stosujemy wartoÅ›ci 0 (brak krawÄ™dzi) i 1 (istnieje krawÄ™dÅº), jednak w przypadku waÅ¼onego grafu moÅ¼emy stosowaÄ‡ inne wartoÅ›ci numeryczne iÂ `null`Â dla braku krawÄ™dzi.

Dla poniÅ¼szego grafu wyglÄ…daÅ‚oby to nastÄ™pujÄ…co: 

|     | A   | B   | C   | D   |
| --- | --- | --- | --- | --- |
| A   | 0   | 1   | 0   | 1   |
| B   | 0   | 0   | 1   | 0   |
| C   | 1   | 0   | 0   | 0   |
| D   | 0   | 0   | 0   | 0   |


```tikz
\usetikzlibrary{arrows.meta}
\begin{document}
\begin{tikzpicture}
\begin{scope}[every node/.style={circle,thick,draw}]
    \node (A) at (0,0) {A};
    \node (B) at (0,3) {B};
    \node (C) at (2.5,2) {C};
    \node (D) at (2.5,-2) {D};
\end{scope}

\begin{scope}[>={Stealth[black]},
              every node/.style={fill=white,circle},
              every edge/.style={draw=black,very thick}]
 \path [->] (A) edge (B);
 \path [->] (A) edge (D);
 \path [->] (B) edge (C);
 \path [->] (C) edge (A);
\end{scope}
\end{tikzpicture}
\end{document}
```

## Relacje binarne, wÅ‚asnoÅ›ci i metody reprezentacji. 

### Iloczyn kartezjaÅ„ski zbiorÃ³w  
RozwaÅ¼a siÄ™ dwa zbiory $X$ i $Y$. ZbiÃ³r wszystkich uporzÄ…dkowanych par elementÃ³w naleÅ¼Ä…cych odpowiednio do tych zbiorÃ³w, nazywa siÄ™ iloczynem (albo produktem) kartezjaÅ„skim zbiorÃ³w $X$ i $Y$. Iloczyn kartezjaÅ„ski oznacza siÄ™ jako $X \times Y$. MoÅ¼na to zapisaÄ‡ w nastÄ™pujÄ…cy sposÃ³b: $X \times Y={(x,y): x \in X \text{ i } y \in Y}$.

$$
% determinant form
\begin{align*}
X \times Y = \{1,2,3,4\} \times \{a,b,c\} =\begin{vmatrix}
(1, a) & (1, b) & (1, c)\\
(2, a) & (2, b) & (2, c)\\
(3, a) & (3, b) & (3, c)\\
(4, a) & (4, b) & (4, c)\\
\end{vmatrix}
\end{align*}
$$
Operacja iloczynu kartezjaÅ„skiego nie jest przemienna.

### Relacje binarne
>[!info] Relacje binarne
 Relacja binarna (dwuargumentowa) to podzbiÃ³r iloczynu kartezjaÅ„skiego dwÃ³ch zbiorÃ³w.
 >
 >JeÅ›li weÅºmiemy $A = X \times Y$ , to $W_{A}$,  oznacza pewnÄ… wÅ‚asnoÅ›Ä‡, a zarazem podzbiÃ³r, iloczynu kartezjaÅ„skiego $X \times Y$ . 
>
>Ten podzbiÃ³r, czyli zbiÃ³r par o pewnej wÅ‚asnoÅ›ci, to wÅ‚aÅ›nie relacja â€” relacja pomiÄ™dzy pierwszÄ… a drugÄ… zmiennÄ… w iloczynie kartezjaÅ„skim.
>Relacje bÄ™dziemy oznaczaÄ‡ greckÄ… literÄ… $\rho$. TakÅ¼e jeÅ›li rozpatrujemy relacjÄ™ \$rho$ pomiÄ™dzy elementami zbioru $X$ a elementami zbioru $Y$ , czyli relacjÄ™ w iloczynie kartezjaÅ„skim $X \times Y$ , to formalnie $\rho \subseteq X \times Y$.
>
>Piszemy
> - $(x, y) \in \rho$ i mÃ³wimy, Å¼e para $(x, y)$ naleÅ¼y do relacji $\rho$, albo piszemy
> - $x \: \rho \: y$ i wtedy mÃ³wimy, Å¼e element $x$ jest w relacji $\rho$ z elementem $y$, dla $x \in X$ oraz $y \in Y$ .

#### WÅ‚asnoÅ›ci relacji
RozwaÅ¼amy relacjÄ™ $\rho \subseteq X \times X$ dla dowolnego zbioru $X$.
- **zwrotnoÅ›Ä‡** Relacja $\rho$ jest zwrotna, $\Longleftrightarrow$ dla kaÅ¼dego $x \in X$ zachodzi $x \: \rho \: x$. Innymi sÅ‚owy, zwrotnoÅ›Ä‡ relacji oznacza, Å¼e kaÅ¼dy element jest w relacji ze sobÄ….
- **symetria** Relacja $\rho$ jest symetryczna, $\Longleftrightarrow$ dla dowolnych $x, y \in X$ jeÅ›li $x \: \rho \: y$, to $y \rho x$. Intuicyjnie, symetria relacji oznacza, Å¼e moÅ¼emy zamieniÄ‡ $x$ z $y$ w parze $(x, y)$ o ile w ogÃ³le $(x, y) \in \rho$. Tak wiÄ™c kolejnoÅ›Ä‡ wystÄ™powania elementÃ³w w relacji nie ma tutaj znaczenia.
- **antysymetria** Relacja $\rho$ jest antysymetryczna, $\Longleftrightarrow$ dla dowolnych $x, y \in X \text{ jeÅ›li } x \: \rho \: y \text{ oraz } y \: \rho \: x, \text{ to } x = y$. Tak wiÄ™c antysymetria relacji oznacza, Å¼e kolejnoÅ›Ä‡ wystÄ™powania rÃ³Å¼nych elementÃ³w w relacji jest istotna. To znaczy, Å¼e dla x 6 = y albo $x \: \rho \: y$, albo $y \: \rho \: x$, albo nie zachodzi ani jedno, ani drugie. 
- **przechodnioÅ›Ä‡** Relacja $\rho$ jest przechodnia, $\Longleftrightarrow$ dla dowolnych $x, y, z \in X$ jeÅ›li $x \: \rho \: y$ oraz $y \: \rho \: z$, to rÃ³wnieÅ¼ $x \: \rho \: z$.

>[!example]
>Niech X = zbiÃ³r wszystkich ludzi (o jasno okreÅ›lonej pÅ‚ci). Dla $x, y \in X$ okreÅ›lamy relacjÄ™ $/rho$ w nastÄ™pujÄ…cy sposÃ³b "$x  \: \rho \: y \Longleftrightarrow x$ jest tej samej pÅ‚ci co $y$".
>- **zwrotnoÅ›Ä‡**: Zawsze czÅ‚owiek $x$ jest tej samej pÅ‚ci co $x$, tzn. $x  \: \rho \: x$, wiÄ™c relacja jest zwrotna.
>- **symetria**: JeÅ›li czÅ‚owiek $x$ jest tej samej pÅ‚ci co czÅ‚owiek $y$, to rÃ³wnieÅ¼ na odwrÃ³t, $y$ jest tej samej pÅ‚ci co $x$. Zatem relacja Ï jest symetryczna.
>- **przechodnioÅ›Ä‡**: ZaÅ‚Ã³Å¼my, Å¼e czÅ‚owiek $x$ jest tej samej pÅ‚ci co $y$ oraz, Å¼e $y$ jest tej samej pÅ‚ci co $z$. WÃ³wczas wszyscy $x, y, z$ sÄ… tej samej pÅ‚ci, w szczegÃ³lnoÅ›ci $x$ jest tej samej pÅ‚ci co $z$. Zatem relacja Ï jest przechodnia.
#### SposÃ³b reprezentacji
 **Grafowa**
 ```tikz
\usetikzlibrary{positioning,chains,fit,shapes,calc}

\begin{document}

\definecolor{myblue}{RGB}{80,80,160}
\definecolor{mygreen}{RGB}{80,160,80}

\begin{tikzpicture}[thick,
  every node/.style={draw,circle},
  fsnode/.style={fill=myblue},
  ssnode/.style={fill=mygreen},
  every fit/.style={ellipse,draw,inner sep=-2pt,text width=2cm},
  ->,shorten >= 3pt,shorten <= 3pt
]

\begin{scope}[start chain=going below,node distance=7mm]
\foreach \i in {1,2,...,4}
  \node[fsnode,on chain] (f\i) [label=left: x\i] {};
\end{scope}

\begin{scope}[xshift=4cm,yshift=-0.5cm,start chain=going below,node distance=7mm]
\foreach \j in {1,2,...,4}
  \node[ssnode,on chain] (s\j) [label=right: y\j] {};
\end{scope}

\node [myblue,fit=(f1) (f4),label=above:$X$] {};
\node [mygreen,fit=(s1) (s4),label=above:$Y$] {};

\draw (f1) -- (s1);
\draw (f2) -- (s2);
\draw (f3) -- (s3);
\draw (f4) -- (s4);
\end{tikzpicture}

\end{document}
```

**Wykres wspÃ³Å‚rzÄ™dnych**
```tikz
\begin{document} 
\begin{tikzpicture}[domain=0:4] 
\draw[very thin,color=gray] (-0.1,-1.1) grid (3.9,3.9); 
\draw[->] (-0.2,0) -- (4.2,0) node[right] {$x$}; 
\draw[->] (0,-1.2) -- (0,4.2) node[above] {$f(x)$}; 
\draw[color=red] plot (\x,{\x}) node[right] {$f(x)=x$};
\end{tikzpicture} \end{document} 
```
**Macierzowa**

$$
\begin{align*}
M_{R} &= (m_{ij})                   \\[.75em]
%
m(i,j) & = \begin{cases}
            1    & (a_{i},b_{j}) \in R        \\[.75em]
            0    & (a_{i},b_{j}) \notin R    \\
           \end{cases}              \\[.75em]
 i &= 1,2,\dots m                   \\[.75em]
 j &= 1,2,\dots n
    \end{align*}
$$

| R | $b_1$ | $b_2$ | $b_3$ |
| ---- | ---- | ---- | ---- |
| $a_1$ | 0 | 1 | 0 |
| $a_2$ | 0 | 0 | 1 |
| $a_3$ | 1 | 0 | 0 |
| $a_4$ | 0 | 0 | 0 |

## Zasada indukcji matematycznej. 
ChcÄ…c udowodniÄ‡ wzÃ³r, w ktÃ³rym zmienna jest liczbÄ… naturalna, najpierw musimy sprawdziÄ‡ czy jest on prawdziwy, dla chociaÅ¼ jednego przypadku (poczÄ…tkowego), czyli dla liczby $n$. JeÅ›li jest to prawdÄ…, to moÅ¼na zaÅ‚oÅ¼yÄ‡, Å¼e jest to prawdÄ… dla liczby naturalnej $k$, ktÃ³ra jest rÃ³wna lub wiÄ™ksza od $n$. WykorzystujÄ…c warunek, Å¼e wzÃ³r jest prawdziwy dla liczby naturalnej $k$, udowadnia siÄ™, Å¼e wzÃ³r jest prawdziwy dla liczby naturalnej $k+1$ (czyli o jeden wiÄ™kszej).  
Jest to o tyle genialna metoda, Å¼e udowadnia w trzech korkach i sprawdza wszystkie liczby naturalne.

Schemat **indukcji matematycznej**:  
1) udowodnienie prawdziwoÅ›ci twierdzenia dla pewnej liczby naturalnej $n$,  
2) zaÅ‚oÅ¼enie, Å¼e twierdzenie jest prawdziwe dla liczby naturalnej ğ‘˜, takiej Å¼e $k \geq n$,  
3) udowodnienie prawdziwoÅ›ci twierdzenia dla $k+1$.
## Twierdzenie Bayesa. 
Tradycyjna metoda obliczania prawdopodobieÅ„stwa warunkowego (prawdopodobieÅ„stwa zajÅ›cia jednego zdarzenia przy zaistnieniu innego zdarzenia) polega na wykorzystaniu wzoru na prawdopodobieÅ„stwo warunkowe, obliczeniu Å‚Ä…cznego prawdopodobieÅ„stwa wystÄ…pienia pierwszego i drugiego zdarzenia w tym samym czasie, a nastÄ™pnie podzieleniu go prawdopodobieÅ„stwem wystÄ…pienia drugiego zdarzenia. Jednak prawdopodobieÅ„stwo warunkowe moÅ¼na rÃ³wnieÅ¼ obliczyÄ‡ w nieco inny sposÃ³b, korzystajÄ…c z twierdzenia Bayesa.

ObliczajÄ…c prawdopodobieÅ„stwo warunkowe za pomocÄ… twierdzenia Bayesa, naleÅ¼y wykonaÄ‡ nastÄ™pujÄ…ce kroki:

- OkreÅ›l prawdopodobieÅ„stwo speÅ‚nienia warunku B, zakÅ‚adajÄ…c, Å¼e warunek A jest prawdziwy.
- OkreÅ›l prawdopodobieÅ„stwo, Å¼e zdarzenie A bÄ™dzie prawdziwe.
- PomnÃ³Å¼ oba prawdopodobieÅ„stwa przez siebie.
- Podziel przez prawdopodobieÅ„stwo wystÄ…pienia zdarzenia B.

Oznacza to, Å¼e wzÃ³r na twierdzenie Bayesa moÅ¼na wyraziÄ‡ w nastÄ™pujÄ…cy sposÃ³b:

$$P(A|B) = \frac{P(B|A)*P(A)}{P(B)}$$

## Testowanie hipotez statystycznych. 

>[!info] Hipotezy statystyczne 
> To **dowolne przypuszczenie dotyczÄ…ce rozkÅ‚adu populacji**. FormuÅ‚owanie hipotezy statystycznej rozpoczyna siÄ™ od zebrania informacji na temat populacji i jej moÅ¼liwego rozkÅ‚adu. DziÄ™ki temu moÅ¼liwe jest zbudowanie zbioru hipotez dopuszczalnych $\Omega$, czyli zbioru rozkÅ‚adÃ³w, ktÃ³re mogÄ… charakteryzowaÄ‡ badanÄ… populacjÄ™. 

**Hipoteza zerowa** â€“ hipoteza, ktÃ³rej prawdziwoÅ›Ä‡ poddajemy w wÄ…tpliwoÅ›Ä‡ i ktÃ³ra jest testowana celem ewentualnego odrzucenia, oznaczana jako

**Hipoteza alternatywna** Â­â€“ hipoteza, ktÃ³ra bÄ™dzie przyjÄ™ta, jeÅ›li odrzucimy hipotezÄ™ zerowÄ…, oznaczana jako  
Hipoteza zerowa i alternatywna majÄ… siÄ™ wzajemnie wykluczaÄ‡  
Staramy siÄ™ udowodniÄ‡ hipotezÄ™ alternatywnÄ…, co pozwoli na odrzucenie hipotezy zerowej. **Odrzucenie hipotezy alternatywnej nie oznacza, Å¼e hipoteza zerowa jest prawdziwa ani faÅ‚szywa** (mÃ³wimy wtedy, Å¼e â€nie moÅ¼emy odrzuciÄ‡ hipotezy zerowejâ€)

**BÅ‚Ä…d I rodzaju** â€“ bÅ‚Ä…d polegajÄ…cy na przyjÄ™ciu Â gdy hipoteza Â jest prawdziwa.  
**Poziom istotnoÅ›ci testu** â€“ prawdopodobieÅ„stwo popeÅ‚nienia bÅ‚Ä™du pierwszego rodzaju, oznaczane greckÄ… literÄ… Î±

**Statystyka testowa** â€“ statystyka, na ktÃ³rej podstawie orzekamy prawdziwoÅ›Ä‡ , oznaczana duÅ¼Ä… literÄ… Z (statystyka to kwantyl danego rozkÅ‚adu. Z karty wzorÃ³w patrzymy na odpowiedni kwantyl, zaleÅ¼ny od poziomu istotnoÅ›ci, i sprawdzamy, czy nasza statystyka testowa jest od niego wiÄ™ksza. To znaczy, Å¼e naleÅ¼y ona do zbioru krytycznego). W zaleÅ¼noÅ›ci od typu hipotezy, mamy rÃ³Å¼ne wzory na statystykÄ™ testowÄ… (mieliÅ›my do tego kartÄ™ wzorÃ³w)


**BÅ‚Ä…d II rodzaju** â€“ bÅ‚Ä…d polegajÄ…cy na przyjÄ™ciu , gdy hipoteza Â jest prawdziwa

Proces testowania hipotez statystycznych skÅ‚ada siÄ™ z kilku krokÃ³w:
- **FormuÅ‚owanie hipotezy**: FormuÅ‚uje siÄ™ hipotezÄ™ na temat parametrÃ³w populacji na podstawie danych teoretycznych lub wczeÅ›niejszych badaÅ„.
- **WybÃ³r statystyki testowej**: Wybiera siÄ™ odpowiedniÄ… statystykÄ™ testowÄ…, ktÃ³ra bÄ™dzie uÅ¼ywana do oceny hipotezy.
- **WybÃ³r poziomu istotnoÅ›ci**: Wybiera siÄ™ poziom istotnoÅ›ci, ktÃ³ry okreÅ›la, jak wysokie prawdopodobieÅ„stwo omyÅ‚ki jesteÅ›my gotowi zaakceptowaÄ‡.
- **Otrzymanie danych empirycznych**: Przeprowadza siÄ™ badanie lub gromadzi dane empiryczne, ktÃ³re bÄ™dÄ… uÅ¼yte do testowania hipotezy.
- **Ocena hipotezy**: PorÃ³wnuje siÄ™ otrzymane dane empiryczne z wartoÅ›ciami teoretycznymi i ocenia, czy hipoteza jest potwierdzona lub odrzucona.
- **Podejmowanie decyzji**: Na podstawie wyniku testu podejmuje siÄ™ decyzjÄ™, czy hipoteza jest potwierdzona lub odrzucona.
## Wyznaczanie przedziaÅ‚Ã³w ufnoÅ›ci.
PrzedziaÅ‚ ufnoÅ›ci jest narzÄ™dziem statystycznym, ktÃ³re sÅ‚uÅ¼y do okreÅ›lenia, jak dokÅ‚adnie znana jest wartoÅ›Ä‡ parametru populacji na podstawie danych empirycznych. PrzedziaÅ‚ ufnoÅ›ci jest okreÅ›lany jako zakres wartoÅ›ci, ktÃ³ry z okreÅ›lonÄ… pewnoÅ›ciÄ… zawiera prawdziwÄ… wartoÅ›Ä‡ parametru populacji.

Wyznaczanie przedziaÅ‚u ufnoÅ›ci moÅ¼na wykonaÄ‡ na kilka sposobÃ³w, w tym:
- Metoda naiwna: PrzedziaÅ‚ ufnoÅ›ci jest wyznaczany na podstawie otrzymanego rozkÅ‚adu danych empirycznych i jest oparty na zaÅ‚oÅ¼eniu, Å¼e jest on bliski rozkÅ‚adowi normalnemu
- Metoda bootstrap: W tej metodzie przedziaÅ‚ ufnoÅ›ci jest wyznaczany na podstawie symulacji danych na podstawie istniejÄ…cych danych empirycznych.
- Metoda kwantyli: W tej metodzie przedziaÅ‚ ufnoÅ›ci jest wyznaczany na podstawie kwantyli rozkÅ‚adu danych empirycznych